{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37d805e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from dotenv import load_dotenv\n",
    "load_dotenv()\n",
    "import os\n",
    "ds_api_key = os.getenv(\"DEEP_SEEK_API_KEY\")\n",
    "openai_api_key = os.getenv(\"OPENAI_API_KEY\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c686427c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_deepseek import ChatDeepSeek\n",
    "from langchain_openai import ChatOpenAI\n",
    "deepseek = ChatDeepSeek(\n",
    "    api_key=ds_api_key,\n",
    "    model=\"deepseek-chat\"\n",
    ")\n",
    "\n",
    "openai = ChatOpenAI(\n",
    "    api_key=openai_api_key,\n",
    "    base_url=\"https://yunwu.ai/v1\",\n",
    "    model_name=\"gpt-5-mini\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7d9e170",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.tools import tool\n",
    "import requests\n",
    "import yaml\n",
    "from pathlib import Path\n",
    "from typing import List, Dict, Any\n",
    "\n",
    "def web_search_tool_kit():\n",
    "    # 建议将 URL 外部化或作为配置\n",
    "    searx_url = \"https://sousuo.emoe.top/search\"\n",
    "    crawl4ai_url = \"http://10.1.2.4:11235/md\"\n",
    "\n",
    "    @tool(parse_docstring=True)\n",
    "    def web_search(query: str, max_results: int = 5, categories: str = \"general\", language: str =\"zh-CN\", engine: str | None = None) -> str:\n",
    "        \"\"\"\n",
    "        利用 SearXNG 引擎进行互联网搜索。适用于获取实时新闻、技术文档或百科知识。\n",
    "\n",
    "        Args:\n",
    "            query (str): 具体的搜索关键词。\n",
    "            max_results (int): 期望返回的结果条数，默认为 5。\n",
    "            categories (str): 搜索类别。可选值: 'general', 'it', 'science', 'news', 'images', 'videos'。\n",
    "            language (str): 搜索语言。默认为 \"zh-CN\"。\n",
    "            engine (str | None): 指定使用的搜索引擎名称，如 \"google\", \"bing\" 等。默认为 None，表示使用默认引擎。\n",
    "\n",
    "        Returns:\n",
    "            str: 格式化的搜索结果列表，每条包含标题、来源链接和内容摘要。\n",
    "        \"\"\"\n",
    "        params = {\n",
    "            \"q\": query,\n",
    "            \"format\": \"json\",\n",
    "            \"engine\": engine,\n",
    "            \"categories\": categories,\n",
    "            \"language\": language,\n",
    "        } if engine else {\n",
    "            \"q\": query,\n",
    "            \"format\": \"json\",\n",
    "            \"categories\": categories,\n",
    "            \"language\": language,\n",
    "        }\n",
    "\n",
    "        try:\n",
    "            response = requests.get(searx_url, params=params, timeout=15)\n",
    "            response.raise_for_status()\n",
    "            raw_results = response.json().get(\"results\", [])\n",
    "        except Exception as e:\n",
    "            return f\"搜索失败: {str(e)}\"\n",
    "\n",
    "        # --- 核心优化：数据清洗 ---\n",
    "        processed_results = []\n",
    "        # 只取前 max_results 条，避免 Token 溢出\n",
    "        for res in raw_results[:max_results]:\n",
    "            # 提取 AI 需要的关键信息\n",
    "            title = res.get(\"title\", \"无标题\")\n",
    "            link = res.get(\"url\", \"无链接\")\n",
    "            snippet = res.get(\"content\", \"无描述\")\n",
    "\n",
    "            # 格式化为易于 AI 阅读的字符串\n",
    "            processed_results.append(f\"标题: {title}\\n链接: {link}\\n摘要: {snippet}\\n---\")\n",
    "\n",
    "        if not processed_results:\n",
    "            return \"未找到相关结果。\"\n",
    "\n",
    "        return \"\\n\".join(processed_results)\n",
    "\n",
    "\n",
    "    @tool(parse_docstring=True)\n",
    "    def web_reader(url: str, priority: int = 1) -> str:\n",
    "        \"\"\"\n",
    "        当你需要阅读特定网页的详细内容时使用此工具。\n",
    "        支持动态加载的网页（如单页应用）。\n",
    "\n",
    "        Args:\n",
    "            url (str): 要读取的完整网页 URL。\n",
    "            priority (int): 爬取优先级，1-10 之间。\n",
    "\n",
    "        Returns:\n",
    "            str: 网页的正文内容（Markdown 格式）。\n",
    "        \"\"\"\n",
    "        payload = {\n",
    "            \"url\": url,\n",
    "            \"f\": \"fit\"\n",
    "        }\n",
    "\n",
    "        try:\n",
    "            response = requests.post(crawl4ai_url, json=payload, timeout=30)\n",
    "            response.raise_for_status()\n",
    "\n",
    "            data = response.json()\n",
    "\n",
    "            if data.get(\"success\") and data.get(\"markdown\"):\n",
    "                content = data.get(\"markdown\", \"\")\n",
    "                if len(content) > 5000:\n",
    "                    return content[:5000] + \"\\n\\n(内容过长，已自动截断...)\"\n",
    "                return content\n",
    "            else:\n",
    "                return f\"未能提取内容: {data.get('error', '未知错误')}\"\n",
    "\n",
    "        except Exception as e:\n",
    "            return f\"读取网页失败: {str(e)}\"\n",
    "\n",
    "    return [web_search, web_reader]\n",
    "\n",
    "def commomon_tool_kit():\n",
    "\n",
    "    @tool\n",
    "    def now():\n",
    "        \"\"\"获取当前的日期和时间。\"\"\"\n",
    "        from datetime import datetime\n",
    "        return datetime.now().strftime(\"%Y-%m-%d %H:%M:%S\")\n",
    "\n",
    "    return [now]\n",
    "\n",
    "def prompt_tool_kit(model=None):\n",
    "    \"\"\"\n",
    "    创建 Meta Prompt 工具包，用于运行提示词工程工作流。\n",
    "\n",
    "    Args:\n",
    "        model: LangChain Chat Model (如 ChatDeepSeek, ChatOpenAI)。如果为 None，使用全局 deepseek。\n",
    "\n",
    "    Returns:\n",
    "        List[Tool]: 包含四个核心工具的列表\n",
    "    \"\"\"\n",
    "    # 使用全局 deepseek 模型作为默认\n",
    "    if model is None:\n",
    "        from langchain_deepseek import ChatDeepSeek\n",
    "        model = deepseek\n",
    "\n",
    "    meta_prompts_dir = Path(\"meta_prompts\")\n",
    "\n",
    "    def load_prompt_template(name: str) -> Dict[str, Any]:\n",
    "        \"\"\"加载 YAML 格式的 prompt 模板\"\"\"\n",
    "        yaml_path = meta_prompts_dir / f\"{name}.yaml\"\n",
    "        with open(yaml_path, 'r', encoding='utf-8') as f:\n",
    "            return yaml.safe_load(f)\n",
    "\n",
    "    def render_messages(template: Dict, **kwargs) -> List[Dict[str, str]]:\n",
    "        \"\"\"渲染消息模板，替换变量占位符\"\"\"\n",
    "        messages = []\n",
    "        for msg in template['messages']:\n",
    "            content = msg['content']\n",
    "            # 替换 {{variable}} 格式的占位符\n",
    "            for key, value in kwargs.items():\n",
    "                content = content.replace(f\"{{{{{key}}}}}\", str(value))\n",
    "            messages.append({\"role\": msg['role'], \"content\": content})\n",
    "        return messages\n",
    "\n",
    "    def call_llm(messages: List[Dict[str, str]]) -> str:\n",
    "        \"\"\"调用 LLM 并返回响应\"\"\"\n",
    "        from langchain_core.messages import HumanMessage, SystemMessage\n",
    "\n",
    "        lc_messages = []\n",
    "        for msg in messages:\n",
    "            if msg['role'] == 'system':\n",
    "                lc_messages.append(SystemMessage(content=msg['content']))\n",
    "            elif msg['role'] == 'user':\n",
    "                lc_messages.append(HumanMessage(content=msg['content']))\n",
    "            elif msg['role'] == 'assistant':\n",
    "                # 历史对话中的 assistant 消息转换为 HumanMessage\n",
    "                lc_messages.append(HumanMessage(content=f\"(Previous assistant response): {msg['content']}\"))\n",
    "\n",
    "        response = model.invoke(lc_messages)\n",
    "        return response.content\n",
    "\n",
    "    # ========== 工具 1: Prompt Architect ==========\n",
    "    @tool(parse_docstring=True)\n",
    "    def prompt_architect(requirement: str) -> str:\n",
    "        \"\"\"\n",
    "        将用户需求转换为精确的技术规格文档 (JSON)。\n",
    "\n",
    "        Args:\n",
    "            requirement (str): 用户的需求描述，支持中文或英文。\n",
    "\n",
    "        Returns:\n",
    "            str: JSON 格式的技术规格文档，包含 input/output schema、task、goal、constraint。\n",
    "        \"\"\"\n",
    "        template = load_prompt_template('prompt_architect')\n",
    "        messages = render_messages(template, requirement=requirement)\n",
    "        return call_llm(messages)\n",
    "\n",
    "    # ========== 工具 2: Data Generator ==========\n",
    "    @tool(parse_docstring=True)\n",
    "    def data_generator(\n",
    "        num: int,\n",
    "        analysis: str,\n",
    "        notion: str = \"Generate diverse test cases covering edge cases\",\n",
    "        require_output: bool = True\n",
    "    ) -> str:\n",
    "        \"\"\"\n",
    "        基于技术规格生成高质量的合成测试数据集。\n",
    "\n",
    "        Args:\n",
    "            num (int): 生成的测试用例数量。\n",
    "            analysis (str): Prompt Architect 生成的技术规格 (JSON)。\n",
    "            notion (str): 特定指令/关注点，如 \"测试边界条件\" 或 \"测试多语言支持\"。\n",
    "            require_output (bool): 是否生成预期输出，默认 True。\n",
    "\n",
    "        Returns:\n",
    "            str: JSON 格式的数据集，包含 dataset 键和测试用例列表。\n",
    "        \"\"\"\n",
    "        template = load_prompt_template('data_generator')\n",
    "        messages = render_messages(\n",
    "            template,\n",
    "            num=num,\n",
    "            analysis=analysis,\n",
    "            notion=notion,\n",
    "            require_output=str(require_output).lower()\n",
    "        )\n",
    "        return call_llm(messages)\n",
    "\n",
    "    # ========== 工具 3: Prompt Builder ==========\n",
    "    @tool(parse_docstring=True)\n",
    "    def prompt_builder(analysis: str, test_data: str) -> str:\n",
    "        \"\"\"\n",
    "        将技术规格和测试数据转换为可直接调用的 messages 列表 (JSON)。\n",
    "\n",
    "        Args:\n",
    "            analysis (str): Prompt Architect 生成的技术规格 (JSON)。\n",
    "            test_data (str): Data Generator 生成的测试数据集 (JSON)。\n",
    "\n",
    "        Returns:\n",
    "            str: JSON 数组，包含完整的 messages 列表，可直接用于 API 调用。\n",
    "        \"\"\"\n",
    "        template = load_prompt_template('prompt_builder')\n",
    "        messages = render_messages(\n",
    "            template,\n",
    "            analysis=analysis,\n",
    "            test_data=test_data\n",
    "        )\n",
    "        return call_llm(messages)\n",
    "\n",
    "    # ========== 工具 4: Prompt Evaluator ==========\n",
    "    @tool(parse_docstring=True)\n",
    "    def prompt_evaluator(\n",
    "        analysis: str,\n",
    "        input_data: str,\n",
    "        actual_output: str,\n",
    "        expected_output: str = \"None provided\"\n",
    "    ) -> str:\n",
    "        \"\"\"\n",
    "        评估 AI Agent 的执行结果，返回评分和改进建议。\n",
    "\n",
    "        Args:\n",
    "            analysis (str): 技术规格文档 (JSON)，包含目标和约束。\n",
    "            input_data (str): 输入给 Agent 的数据。\n",
    "            actual_output (str): Agent 实际生成的输出。\n",
    "            expected_output (str): 预期的正确答案（可选）。\n",
    "\n",
    "        Returns:\n",
    "            str: JSON 格式的评估报告，包含 reasoning、issues、suggestions、score (0-100)。\n",
    "        \"\"\"\n",
    "        template = load_prompt_template('prompt_evaluator')\n",
    "        messages = render_messages(\n",
    "            template,\n",
    "            analysis=analysis,\n",
    "            input_data=input_data,\n",
    "            expected_output=expected_output,\n",
    "            actual_output=actual_output\n",
    "        )\n",
    "        return call_llm(messages)\n",
    "\n",
    "    return [prompt_architect, data_generator, prompt_builder]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c2faacb",
   "metadata": {},
   "outputs": [],
   "source": [
    "from deepagents import create_deep_agent\n",
    "from langfuse.langchain import CallbackHandler\n",
    "ds_agent = create_deep_agent(\n",
    "    name=\"deepseek-agent\",\n",
    "    model=deepseek,\n",
    "    tools=prompt_tool_kit(deepseek) + web_search_tool_kit(),\n",
    "    system_prompt=\"你是一个提示词生成专家,有一系列工具供你使用,对于用户提出的需求,你无需再和用户交流,全自动借用工具完成任务, 考虑优先使用提示词工程工具包中的工具, 理想流程为先使用Prompt Architect生成技术规格,再使用Data Generator生成测试数据,然后使用Prompt Builder生成最终提示词\",\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c814373b",
   "metadata": {},
   "outputs": [],
   "source": [
    "ds_agent.invoke({\n",
    "    \"messages\" : [\n",
    "        {\"role\": \"user\", \"content\": \"我需要一个提示词,他的功能是帮助用户准确翻译英文博客,输入是经过处理的markdown英文文本,输出是翻译后的中文markdown文本\"}]\n",
    "},\n",
    "config={\"callbacks\": [CallbackHandler()]}\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48f80ce6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from deepagents.backends import CompositeBackend, StateBackend, StoreBackend, FilesystemBackend\n",
    "from langgraph.store.memory import InMemoryStore\n",
    "from deepagents import create_deep_agent\n",
    "from langfuse.langchain import CallbackHandler\n",
    "composite_backend = lambda rt: CompositeBackend(\n",
    "    default=StateBackend(rt),\n",
    "    routes={\n",
    "        \"/memories/\": FilesystemBackend(root_dir=\"/home/zhonghan.chen/code/promptx/reports\", virtual_mode=True),\n",
    "    }\n",
    ")\n",
    "search_agent = create_deep_agent(\n",
    "    name=\"search-agent\",\n",
    "    model=deepseek,\n",
    "    backend=composite_backend,\n",
    "    store=InMemoryStore(),\n",
    "    tools=web_search_tool_kit() + commomon_tool_kit(),\n",
    "    system_prompt=\"你是一个互联网搜索专家,有一系列工具供你使用,对于用户提出的需求,你无需再和用户交流,全自动借用工具完成任务,当你认为任务完成时,将报告写入/memories/xxx_report.md\",\n",
    ")\n",
    "\n",
    "search_agent.invoke({\n",
    "    \"messages\" : [\n",
    "        {\"role\": \"user\", \"content\": \"请帮我搜索关于最近clawd bot技术发展的新闻,并生成一份包含主要内容的报告\"}]\n",
    "    },\n",
    "config={\"callbacks\": [CallbackHandler()]}\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "promptx",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
